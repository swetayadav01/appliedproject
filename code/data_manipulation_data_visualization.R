# packages required for basic data manipuldation
require(stats)
require(plyr)
require(dplyr) 
require(geosphere)
require(reshape)
require(tibble)
require(stringr)
require(SnowballC)
require(tidytext)
require(tidyr)

#packages required for basic visualization
require(extrafont) 
require(RColorBrewer)
require(ggplot2) 
require(GGally)
require(grid)

#packages required for mapdata
require(maps)
require(mapdata)


#multiplot function
multiplot <- function(..., plotlist = NULL, file, cols = 1, layout = NULL) {
  require(grid)
  plots <- c(list(...), plotlist)
  numPlots = length(plots)
  if (is.null(layout)) {
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                     ncol = cols, nrow = ceiling(numPlots/cols))}
  if (numPlots == 1) { print(plots[[1]])
  } else {
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))
    
    for (i in 1:numPlots) {
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))
      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col)) }}}
ezLev <- function(x,new_order){
  for(i in rev(new_order)){
    x=relevel(x,ref=i)
  }
  return(x)
}
ggcorplot <- function(data,var_text_size,cor_text_limits){

  # normalize the data
  
  for(i in 1:length(data)){
    data[,i]=(data[,i]-mean(data[,i]))/sd(data[,i])
  }
  # obtain new data frame
  z=data.frame()
  i = 1
  j = i
  while(i<=length(data)){
    if(j>length(data)){
      i=i+1
      j=i
    }else{
      x = data[,i]
      y = data[,j]
      temp=as.data.frame(cbind(x,y))
      temp=cbind(temp,names(data)[i],names(data)[j])
      z=rbind(z,temp)
      j=j+1
    }
  }
  names(z)=c('x','y','x_lab','y_lab')
  z$x_lab = ezLev(factor(z$x_lab),names(data))
  z$y_lab = ezLev(factor(z$y_lab),names(data))
  z=z[z$x_lab!=z$y_lab,]
  
  #obtain correlation values
  
  z_cor = data.frame()
  i = 1
  j = i
  while(i<=length(data)){
    if(j>length(data)){
      i=i+1
      j=i
    }else{
      x = data[,i]
      y = data[,j]
      x_mid = min(x)+diff(range(x))/2
      y_mid = min(y)+diff(range(y))/2
      this_cor = cor(x,y)
      this_cor.test = cor.test(x,y)
      this_col = ifelse(this_cor.test$p.value<.05,'<.05','>.05')
      this_size = (this_cor)^2
      cor_text = ifelse(
        this_cor>0
        ,substr(format(c(this_cor,.123456789),digits=2)[1],2,4)
        ,paste('-',substr(format(c(this_cor,.123456789),digits=2)[1],3,5),sep='')
      )
      b=as.data.frame(cor_text)
      b=cbind(b,x_mid,y_mid,this_col,this_size,names(data)[j],names(data)[i])
      z_cor=rbind(z_cor,b)
      j=j+1
    }
  }
  names(z_cor)=c('cor','x_mid','y_mid','p','rsq','x_lab','y_lab')
  z_cor$x_lab = ezLev(factor(z_cor$x_lab),names(data))
  z_cor$y_lab = ezLev(factor(z_cor$y_lab),names(data))
  diag = z_cor[z_cor$x_lab==z_cor$y_lab,]
  z_cor=z_cor[z_cor$x_lab!=z_cor$y_lab,]
  #start creating layers
  points_layer = layer(
    geom = 'point'
    , data = z
    , mapping = aes(
      x = x
      , y = y
    )
  )
  lm_line_layer = layer(
    geom = 'line'
    , geom_params = list(colour = 'red')
    , stat = 'smooth'
    , stat_params = list(method = 'lm')
    , data = z
    , mapping = aes(
      x = x
      , y = y
    )
  )
  lm_ribbon_layer = layer(
    geom = 'ribbon'
    , geom_params = list(fill = 'green', alpha = .5)
    , stat = 'smooth'
    , stat_params = list(method = 'lm')
    , data = z
    , mapping = aes(
      x = x
      , y = y
    )
  )
  cor_text = layer(
    geom = 'text'
    , data = z_cor
    , mapping = aes(
      x=y_mid
      , y=x_mid
      , label=cor
      , size = rsq
      , colour = p
    )
  )
  var_text = layer(
    geom = 'text'
    , geom_params = list(size=var_text_size)
    , data = diag
    , mapping = aes(
      x=y_mid
      , y=x_mid
      , label=x_lab
    )
  )
  f = facet_grid(y_lab~x_lab,scales='free')
  o = opts(
    panel.grid.minor = theme_blank()
    ,panel.grid.major = theme_blank()
    ,axis.ticks = theme_blank()
    ,axis.text.y = theme_blank()
    ,axis.text.x = theme_blank()
    ,axis.title.y = theme_blank()
    ,axis.title.x = theme_blank()
    ,legend.position='none'
  )
  
  size_scale = scale_size(limits = c(0,1),to=cor_text_limits)
  return(
    ggplot()+
      points_layer+
      lm_ribbon_layer+
      lm_line_layer+
      var_text+
      cor_text+
      f+
      o+
      size_scale
  )
}


#load data

trv <- data.frame(read.csv("C:/Users/Sweta/Desktop/Final Project/Data/training_variants"))
tev <- data.frame(read.csv("C:/Users/Sweta/Desktop/Final Project/Data/test_variants"))

temp <- readLines("C:/Users/Sweta/Desktop/Final Project/Data/training_text")
temp <- str_split_fixed(temp[2:length(temp)], "\\|\\|",2)
trxt <- data_frame(ID=temp[,1], text=temp[,2])

temp <- readLines("C:/Users/Sweta/Desktop/Final Project/Data/test_text")
temp <- str_split_fixed(temp[2:length(temp)], "\\|\\|",2)
text <- data_frame(ID=temp[,1], text=temp[,2])

#checking the data
glimpse(trv)
glimpse(trxt)

glimpse(tev)
glimpse(text)

# checking null values
sum(is.na(trv))
sum(is.na(tev))

##Check data
#Checking some variables - Gene&Variation by length  before visulization

length(unique(trv$Gene))
length(unique(tev$Gene))
length(intersect(unique(tev$Gene), unique(trv$Gene)))
length(union(unique(tev$Gene), unique(trv$Gene)))

length(unique(trv$Variation))
length(unique(tev$Variation))
length(intersect(unique(tev$Variation), unique(trv$Variation)))
length(union(unique(tev$Variation), unique(trv$Variation)))

#Variation seems not meaningful variable for learning yet.

trv %>%
  group_by(Gene) %>%
  count() %>%
  summary()

trv %>%
  group_by(Variation) %>%
  count() %>%
  summary()

trv %>%
  group_by(Class) %>%
  count() %>%
  summary()

gene_freq <- trv %>% #check Gene frequency
  group_by(Gene) %>%
  count() %>%
  arrange(desc(n)) %>%
  head(n=20) %>%
  ggplot(aes(reorder(Gene, n),n , fill=Gene)) + 
  geom_col() + 
  geom_text(aes(label=n), size = 3, position = position_stack(vjust = 0.5)) +
  coord_flip() +
  theme_gray(base_family = "Helvetica") +
  theme(legend.position="none") + 
  labs(title="histogram")

var_freq <- trv %>% #check Variation frequency 
  group_by(Variation) %>%
  count() %>%
  arrange(desc(n)) %>%
  head(n=20) %>%
  ggplot(aes(reorder(Variation, n),n , fill=Variation)) + 
  geom_col() + 
  geom_text(aes(label=n), size = 3, position = position_stack(vjust = 0.5)) +
  coord_flip() +
  theme_gray(base_family = "Helvetica") +
  theme(legend.position="none") + 
  labs(title="histogram")

class_freq <- trv %>%
  group_by(Class) %>%
  count() %>%
  ggplot(aes(reorder(Class, -as.numeric(Class)),n , fill=Class)) + 
  geom_col() + 
  geom_text(aes(label=n), size = 3, color="white", position = position_stack(vjust = 0.5)) +
  coord_flip() +
  theme_gray(base_family = "Helvetica") +
  theme(legend.position="none") + 
  labs(title="histogram")

layout <- matrix(c(1,2,3),1,3,byrow=TRUE)
multiplot(gene_freq, var_freq, class_freq, layout=layout)

#In Gene feature, It shows not bad distribution compared with Variation. we can try to use it.

#Gene/Variation frequency comparison of training & test set

tr_10_gene <- trv %>%
  count(Gene) %>%
  arrange(desc(n)) %>%
  head(n=10) %>%
  mutate(div="tr")

te_10_gene <- tev %>%
  count(Gene) %>%
  arrange(desc(n)) %>%
  head(n=10) %>%
  mutate(div="te")

gene_compare <- data.frame(rbind(te_10_gene, tr_10_gene)) %>%
  ggplot(aes(x=Gene, y=n, group=div, fill=div, color=div)) + 
  geom_line()

tr_10_var <- trv %>%
  count(Variation) %>%
  arrange(desc(n)) %>%
  head(n=10) %>%
  mutate(div="tr") 

te_10_var <- tev %>%
  count(Variation) %>%
  arrange(desc(n)) %>%
  head(n=10) %>%
  mutate(div="te")

var_compare <- data.frame(rbind(te_10_var, tr_10_var)) %>%
  ggplot(aes(x=Variation, y=n, group=div, fill=div, color=div)) + 
  geom_line()

layout <- matrix(c(1,2),1,2,byrow=TRUE)
multiplot(gene_compare, var_compare)


gene_tr_class <- trv %>%
  filter(Gene %in% as.character(tr_10_gene$Gene)) %>%
  ggplot(aes(Gene)) +
  geom_bar() +
  scale_y_log10() +
  theme(axis.text.x  = element_text(angle=90, vjust=0.5, size=7)) +
  facet_wrap(~ Class)

var_tr_class <- trv %>%
  filter(Variation %in% as.character(tr_10_var$Variation)) %>%
  ggplot(aes(Variation)) +
  geom_bar() +
  scale_y_log10() +
  theme(axis.text.x  = element_text(angle=90, vjust=0.5, size=7)) +
  facet_wrap(~Class)

layout <- matrix(c(1,2),1,2,byrow=TRUE)
multiplot(gene_tr_class, var_tr_class)


##Visualization for Word & Bigram

trxt %>%
  mutate(text_len=str_length(text)) %>%
  summary()

trxt %>%
  mutate(text_len=str_length(text)) %>%
  filter(text_len<=100) %>%
  select(ID, text, text_len)

text %>%
  mutate(text_len=str_length(text)) %>%
  summary()

text %>%
  mutate(text_len=str_length(text)) %>%
  filter(text_len<=100) %>%
  select(ID, text, text_len)

trxt %>%
  merge(trv, by="ID") %>%
  select(ID, text, Class) %>%
  mutate(text_len=str_length(text)) %>%
  ggplot(aes(text_len, fill=as.factor(Class))) +
  geom_histogram(bins=50) + 
  facet_wrap(~Class)


tr_word_token <- trxt %>% merge(trv, by="ID") %>%
  select(ID, text, Class) %>%
  unnest_tokens(word, text) %>%
  mutate(word=wordStem(word))

te_word_token <- text %>% 
  unnest_tokens(word, text) %>%
  mutate(word=wordStem(word))

top_word <- function(x, y){ 
  temp <- x %>% 
    unnest_tokens(word, text, to_lower=TRUE) %>%
    mutate(word=wordStem(word)) %>%
    group_by(word) %>%
    count() %>%
    arrange(desc(n)) %>%
    head(n=y) %>%
    select(word, n)
  
  return(temp)
}
top_20_word <- top_word(trxt, 20)  
test_top_20 <- top_word(text, 20)  
intersect(top_20_word$word, test_top_20$word)
#Both top_10_word of training and test set are same and those top 10 word looks like stop_words such as "and", "the", "of" etc.

tr_word_token %>%
  filter(word %in% top_20_word$word) %>%
  count(Class, word) %>%
  ggplot(aes(x=word, y=n, fill=as.factor(Class))) +
  geom_bar(stat="identity") +
  scale_y_log10() +
  theme(axis.text.x  = element_text(angle=90, vjust=0.5, size=7)) +
  facet_wrap(~ Class)
#top_20_word distribution by Class looks similar, so we'd better remove those words.

data("stop_words")
tr_word_token <-  tr_word_token %>% 
  filter(!word %in% top_20_word$word) %>%
  filter(!word %in% stop_words$word) 

# discarding the top_20_words and stop_words 

word_filter <- tr_word_token %>%
  count(ID, word) %>%
  bind_tf_idf(word, ID, n) %>%
  select(word, tf_idf) %>%
  unique() %>%
  arrange(tf_idf) %>% 
  select(word) %>%
  unique() %>%
  head(n=30)

word_filter$word

tr_word_token %>%
  filter(word %in% word_filter$word) %>%
  count(Class, word) %>%
  group_by(Class) %>%
  top_n(20, n) %>%
  ggplot(aes(x=word, y=n, fill=as.factor(Class))) +
  geom_bar(stat="identity") +
  scale_y_log10() +
  theme(axis.text.x  = element_text(angle=90, vjust=0.5, size=7)) +
  facet_wrap(~ Class) +
  coord_flip()

class_word <- tr_word_token %>%
  filter(!word %in% word_filter$word) %>%
  count(Class, word) %>%
  arrange(Class, desc(n)) %>%
  group_by(Class) %>%
  top_n(20, n) 

class_word %>%
  group_by(Class) %>% 
  top_n(20, n) %>%
  arrange(word) %>%
  ggplot(aes(word, n, fill = as.factor(Class))) +
  geom_col() +
  labs(x = NULL, y = "n") +
  theme(legend.position = "none") +
  facet_wrap(~ Class, ncol=3, scales="free") +
  coord_flip()

#Below code shows different frequency by Class

tr_word_token %>%
  count(ID, word) %>%
  filter(word=="tumor") %>%
  merge(trv, by="ID") %>%
  select(Class, word, n) %>%
  group_by(Class) %>%
  mutate(t_m = mean(n)) %>%
  select(Class, word, t_m) %>%
  unique()
head(tr_word_token)

#top 20 words per each Class by their frequencies.

#below code is for extracted top 20 words per each Class by tf_idf

class_word_tf <- tr_word_token %>%
  filter(!word %in% word_filter$word) %>%
  count(ID, word) %>%
  bind_tf_idf(word, ID, n) %>%
  merge(trv, by="ID") %>%
  select(word, tf_idf, Class) %>%
  distinct(Class, word, .keep_all=TRUE) %>%
  group_by(Class) %>%
  top_n(20, tf_idf) %>% 
  arrange(Class, desc(tf_idf))

tr_word_token %>%
  filter(word %in% class_word_tf$word) %>%
  count(ID, word) %>%
  merge(trv, by="ID") %>%
  select(-Gene, -Variation) %>%
  group_by(Class) %>%
  top_n(20, n) %>%
  ungroup() %>%
  ggplot(aes(word, n, fill=as.factor(Class))) +
  geom_col() + 
  labs(x = NULL, y = "n") +
  theme(legend.position = "none") +
  facet_wrap(~ Class, ncol=3, scales="free") +
  coord_flip()


word_n <- trxt %>%
  unnest_tokens(word, text, token="words") %>%
  count(ID) %>%
  mutate(word_n = n) %>%
  select(ID, word_n)

sentence_n <- trxt %>%
  unnest_tokens(sentence, text, token="sentences") %>%
  count(ID) %>%
  mutate(sentence_n = n) %>%
  select(ID, sentence_n)

tr_feature <- trv %>%
  merge(trxt, by="ID") %>%
  mutate(text_len = str_length(text)) %>%
  merge(word_n, by="ID") %>%
  merge(sentence_n, by="ID") %>%
  select(ID, Gene, Variation, text_len, word_n, sentence_n, Class)

feature_refining <- function(x, y){ 
  #x : trxt, text
  #y : trv, tev
  
  word_n <- x %>%
    unnest_tokens(word, text, token="words") %>%
    count(ID) %>%
    mutate(word_n = n) %>%
    select(ID, word_n)
  
  sentence_n <- x %>%
    unnest_tokens(sentence, text, token="sentences") %>%
    count(ID) %>%
    mutate(sentence_n = n) %>%
    select(ID, sentence_n)
  
  feature <- y %>%
    merge(x, by="ID") %>%
    mutate(text_len = str_length(text)) %>%
    merge(word_n, by="ID") %>%
    merge(sentence_n, by="ID") %>%
    select(ID, Gene, Variation, text_len, word_n, sentence_n)
  
  return(feature)
}
te_feature <- feature_refining(text, tev)

##visualization of text_length, word_n and sentence_n

text_len_boxplot <- tr_feature %>%
  mutate(Class=as.factor(Class)) %>%
  ggplot(aes(Class, text_len, group=Class, fill=Class)) +
  geom_boxplot() +
  theme(legend.position="none") +
  scale_y_log10() + 
  coord_flip() + 
  stat_summary(fun.y=mean, colour="darkred", geom="point", shape=18, size=3, show.legend = FALSE) + 
  labs(title="text_len")

word_n_boxplot <- tr_feature %>%
  mutate(Class=as.factor(Class)) %>%
  ggplot(aes(Class, word_n, group=Class, fill=Class)) +
  geom_boxplot() +
  theme(legend.position="none") +
  coord_flip() + 
  stat_summary(fun.y=mean, colour="darkred", geom="point", shape=18, size=3, show.legend = FALSE) + 
  labs(title="word_n")

sentence_n_boxplot <- tr_feature %>%
  mutate(Class=as.factor(Class)) %>%
  ggplot(aes(Class, sentence_n, group=Class, fill=Class)) +
  geom_boxplot() +
  theme(legend.position="none") +
  coord_flip() + 
  stat_summary(fun.y=mean, colour="darkred", geom="point", shape=18, size=3, show.legend = FALSE) + 
  labs(title="sentence_n")

n_pairs <- tr_feature %>%
  select(text_len, word_n, sentence_n) %>%
  ggpairs()

layout <- matrix(c(1,2,3,4,4,4),2,3,byrow=TRUE)
multiplot(text_len_boxplot, word_n_boxplot, sentence_n_boxplot, n_pairs, layout=layout)


head(stop_words$word)
head(top_20_word$word)

##bigram

tr_bigram_token <- trxt %>% 
  select(ID, text) %>% 
  unnest_tokens(bigram, text, token = "ngrams", n = 2) %>%
  separate(bigram, c('w1','w2'), sep=" ") %>%
  mutate(w1=wordStem(w1)) %>%
  mutate(w2=wordStem(w2)) %>%
  filter(!w1 %in% stop_words$word) %>%
  filter(!w2 %in% stop_words$word) %>%
  filter(!w1 %in% top_20_word$word) %>%
  filter(!w2 %in% top_20_word$word) %>%
  unite(bigram, w1, w2, sep=" ")

#below graph shows the bigram distribution by class 

tr_bigram_token %>%
  merge(trv, by="ID") %>%
  select(-Gene, -Variation) %>%
  count(Class, bigram) %>%
  group_by(Class) %>%
  top_n(10, n) %>%
  ungroup() %>%
  ggplot(aes(bigram, n, fill=as.factor(Class))) +
  geom_col() + 
  labs(x = NULL, y = "n") +
  theme(legend.position = "none") +
  facet_wrap(~ Class, ncol=3, scales="free_y") +
  coord_flip()

#below code is for making bigram_filter

bigram_filter <- tr_bigram_token %>%
  count(ID, bigram) %>%
  bind_tf_idf(bigram, ID, n) %>%
  select(bigram, tf_idf) %>%
  unique() %>%
  arrange(tf_idf) %>% 
  select(bigram) %>%
  unique() %>%
  head(n=15)

bigram_filter$bigram

#below graph shows frequency of bigram in bigram_filter by Class

tr_bigram_token %>%
  filter(bigram %in% bigram_filter$bigram) %>%
  merge(trv, by="ID") %>%
  select(-Gene, -Variation) %>%
  count(Class, bigram) %>%
  ggplot(aes(bigram, n, fill=as.factor(Class))) +
  geom_col() + 
  labs(x = NULL, y = "n") +
  theme(legend.position = "none") +
  facet_wrap(~ Class, ncol=3, scales="free") +
  coord_flip()

#below graph shows distribution of bigram filtered using bigram_filter

tr_bigram_token %>%
  filter(!bigram %in% bigram_filter$bigram) %>%
  merge(trv, by="ID") %>%
  select(-Gene, -Variation) %>%
  count(Class, bigram) %>%
  group_by(Class) %>%
  top_n(20, n) %>%
  ungroup() %>%
  ggplot(aes(bigram, n, fill=as.factor(Class))) +
  geom_col() + 
  labs(x = NULL, y = "n") +
  theme(legend.position = "none") +
  facet_wrap(~ Class, ncol=3, scales="free") +
  coord_flip()

#below 'tbt_fted' is filtered using word_filter
tbt_fted <- tr_bigram_token %>%
  separate(bigram, c("w1","w2"), sep=" ") %>%
  filter(!w1 %in% word_filter$word) %>%
  filter(!w2 %in% word_filter$word) %>%
  unite(bigram, w1, w2, sep=" ")

tbt_fted %>%
  merge(trv, by="ID") %>%
  select(-Gene, -Variation) %>%
  count(Class, bigram) %>%
  group_by(Class) %>%
  top_n(20, n) %>%
  ungroup() %>%
  ggplot(aes(bigram, n, fill=as.factor(Class))) +
  geom_col() + 
  labs(x = NULL, y = "n") +
  theme(legend.position = "none") +
  facet_wrap(~ Class, ncol=3, scales="free") +
  coord_flip()

tr_bigram_token <- tr_bigram_token %>%
  filter(!bigram %in% bigram_filter$bigram)

class_bigram <- tr_bigram_token %>%
  merge(trv, by="ID") %>%
  select(-Gene, -Variation, -ID) %>%
  count(Class, bigram) %>%
  distinct(Class, bigram, .keep_all=TRUE) %>%
  group_by(Class) %>%
  top_n(20, n) %>%
  arrange(Class, desc(n))

#below code is for extracted top 20 bigrams per each Class by tf_idf.

class_bigram_tf <- tr_bigram_token %>%
  merge(trv, by="ID") %>%
  select(ID, bigram, Class) %>%
  count(Class, bigram) %>%
  bind_tf_idf(bigram, Class, n) %>%
  select(bigram, tf_idf, Class) %>%
  distinct(Class, bigram, .keep_all=TRUE) %>%
  group_by(Class) %>%
  top_n(20, tf_idf) %>%
  arrange(Class, desc(tf_idf))


tr_bigram_token %>%
  merge(trv, by="ID") %>%
  select(-Gene, -Variation) %>%
  group_by(Class) %>%
  filter(bigram %in% class_bigram_tf$bigram) %>%
  top_n(20, n) %>%
  ungroup() %>%
  ggplot(aes(bigram, n, fill=as.factor(Class))) +
  geom_col() + 
  labs(x = NULL, y = "n") +
  theme(legend.position = "none") +
  facet_wrap(~ Class, ncol=3, scales="free") +
  coord_flip()


trunc_feature <- function(x){
  temp <- head(x, n=0)
  names(temp) <- names(x)
  
  for(i in c(1:9)){
    c <- x %>%
      filter(Class==i)
    if(nrow(c)>20){
      c <- head(c, n=20)
    }
    
    temp <- rbind(temp, c)
  }
  return(temp)
}

class_word <- trunc_feature(class_word)
class_word_tf <- trunc_feature(class_word_tf)
class_bigram <- trunc_feature(class_bigram)
class_bigram_tf <- trunc_feature(class_bigram_tf)
